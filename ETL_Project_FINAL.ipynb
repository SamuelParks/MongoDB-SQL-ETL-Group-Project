{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL Project: TrueSafeCars.com\n",
    "Group 8 (NoFloods)\n",
    "* Roopa Patel\n",
    "* Samuel Parks\n",
    "* Steven Lee\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRACT Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our input datasets and load into dataframes\n",
    "# NOTE: Cars1 refers to a dataset of cars that were scraped from TrueCar.com\n",
    "#       Cars2 refers to a dataset of cars that were scraped from Craigslist\n",
    "\n",
    "# Paths to our vehicle inventory datasets\n",
    "input_file_truecar = os.path.join(\".\", \"Datasets\", \"true_car_listings.csv\")\n",
    "input_file_craigslist = os.path.join(\".\", \"Datasets\", \"vehicles.csv\")\n",
    "\n",
    "# Path to our State to Main Office relationship file\n",
    "main_office_input = os.path.join(\".\", \"TrueSafeCar Main Offices\", \"TrueSafeCar_Main_Offices.csv\")\n",
    "\n",
    "# Read files into dataframes\n",
    "truecar_df = pd.read_csv(input_file_truecar)\n",
    "craigslist_df = pd.read_csv(input_file_craigslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrueCar dataframe beginning number of rows: 852122\n",
      "TrueCar total unique VIN records: 852075\n",
      "\n",
      "Craigslist dataframe beginning number of rows: 539759\n",
      "Craigslist dataframe total unique VIN records: 181678\n"
     ]
    }
   ],
   "source": [
    "# Output Preliminary statistics\n",
    "\n",
    "# Row counts and unique VINs\n",
    "print(f\"TrueCar dataframe beginning number of rows: {truecar_df.shape[0]}\")\n",
    "total_true_car_VINs = len(truecar_df[\"Vin\"].unique())\n",
    "print(f\"TrueCar total unique VIN records: {total_true_car_VINs}\\n\")\n",
    "\n",
    "print(f\"Craigslist dataframe beginning number of rows: {craigslist_df.shape[0]}\")\n",
    "total_craigslist_VINs = len(craigslist_df[\"vin\"].unique())\n",
    "print(f\"Craigslist dataframe total unique VIN records: {total_craigslist_VINs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make\n",
       "AM                   19\n",
       "Acura             11049\n",
       "Alfa                 44\n",
       "Aston               149\n",
       "Audi              12618\n",
       "BMW               32415\n",
       "Bentley             367\n",
       "Buick             12491\n",
       "Cadillac          15047\n",
       "Chevrolet        102268\n",
       "Chrysler          16357\n",
       "Dodge             34368\n",
       "FIAT               1782\n",
       "Ferrari             345\n",
       "Fisker               19\n",
       "Ford             110432\n",
       "Freightliner         11\n",
       "GMC               29008\n",
       "Genesis             141\n",
       "Geo                   2\n",
       "HUMMER              949\n",
       "Honda             50193\n",
       "Hyundai           35837\n",
       "INFINITI          12258\n",
       "Isuzu                76\n",
       "Jaguar             2200\n",
       "Jeep              40373\n",
       "Kia               28636\n",
       "Lamborghini         121\n",
       "Land               4096\n",
       "Lexus             20641\n",
       "Lincoln            7120\n",
       "Lotus                42\n",
       "MINI               4375\n",
       "Maserati           1047\n",
       "Maybach              10\n",
       "Mazda             13365\n",
       "McLaren              47\n",
       "Mercedes-Benz     26323\n",
       "Mercury            1076\n",
       "Mitsubishi         4080\n",
       "Nissan            66250\n",
       "Oldsmobile          122\n",
       "Plymouth             51\n",
       "Pontiac            1783\n",
       "Porsche            4106\n",
       "Ram               19808\n",
       "Rolls-Royce          92\n",
       "Saab                260\n",
       "Saturn              963\n",
       "Scion              3043\n",
       "Subaru            16428\n",
       "Suzuki              334\n",
       "Tesla               231\n",
       "Toyota            77786\n",
       "Volkswagen        23249\n",
       "Volvo              5106\n",
       "smart               713\n",
       "Name: Vin, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts by car make - TrueCar\n",
    "truecar_grouped_by_make = truecar_df.groupby(['Make'])\n",
    "truecar_count_by_make = truecar_grouped_by_make[\"Vin\"].count()\n",
    "truecar_count_by_make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "manufacturer\n",
       "acura               2371\n",
       "alfa-romeo            68\n",
       "aston-martin          20\n",
       "audi                3915\n",
       "bmw                 9135\n",
       "buick               4505\n",
       "cadillac            4737\n",
       "chevrolet          45185\n",
       "chrysler            4760\n",
       "datsun                25\n",
       "dodge              10599\n",
       "ferrari               45\n",
       "fiat                 645\n",
       "ford               58361\n",
       "gmc                14481\n",
       "harley-davidson      152\n",
       "hennessey              0\n",
       "honda              14042\n",
       "hyundai             8360\n",
       "infiniti            2755\n",
       "jaguar               642\n",
       "jeep               15592\n",
       "kia                 6323\n",
       "land rover             5\n",
       "lexus               3908\n",
       "lincoln             2009\n",
       "mazda               3785\n",
       "mercedes-benz       7405\n",
       "mercury              799\n",
       "mini                1563\n",
       "mitsubishi          1597\n",
       "morgan                 2\n",
       "nissan             17351\n",
       "pontiac             1488\n",
       "porche                 6\n",
       "ram                17325\n",
       "rover               1346\n",
       "saturn               810\n",
       "subaru              7004\n",
       "tesla                202\n",
       "toyota             23626\n",
       "volkswagen          6457\n",
       "volvo               1713\n",
       "Name: vin, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts by car make - Craigslist\n",
    "craigslist_grouped_by_make = craigslist_df.groupby(['manufacturer'])\n",
    "craigslist_count_by_make = craigslist_grouped_by_make[\"vin\"].count()\n",
    "craigslist_count_by_make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSFORM Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "BEFORE Column name cleanup:\n",
      "---------------------------------\n",
      "TrueCar dataframe columns:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 852122 entries, 0 to 852121\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   Price    852122 non-null  int64 \n",
      " 1   Year     852122 non-null  int64 \n",
      " 2   Mileage  852122 non-null  int64 \n",
      " 3   City     852122 non-null  object\n",
      " 4   State    852122 non-null  object\n",
      " 5   Vin      852122 non-null  object\n",
      " 6   Make     852122 non-null  object\n",
      " 7   Model    852122 non-null  object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 52.0+ MB\n",
      "None\n",
      "\n",
      "Craigslist dataframe columns:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 539759 entries, 0 to 539758\n",
      "Data columns (total 25 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id            539759 non-null  int64  \n",
      " 1   url           539759 non-null  object \n",
      " 2   region        539759 non-null  object \n",
      " 3   region_url    539759 non-null  object \n",
      " 4   price         539759 non-null  int64  \n",
      " 5   year          538772 non-null  float64\n",
      " 6   manufacturer  516175 non-null  object \n",
      " 7   model         531746 non-null  object \n",
      " 8   condition     303707 non-null  object \n",
      " 9   cylinders     321264 non-null  object \n",
      " 10  fuel          536366 non-null  object \n",
      " 11  odometer      440783 non-null  float64\n",
      " 12  title_status  536819 non-null  object \n",
      " 13  transmission  535786 non-null  object \n",
      " 14  vin           315349 non-null  object \n",
      " 15  drive         383987 non-null  object \n",
      " 16  size          168550 non-null  object \n",
      " 17  type          392290 non-null  object \n",
      " 18  paint_color   365520 non-null  object \n",
      " 19  image_url     539740 non-null  object \n",
      " 20  description   539738 non-null  object \n",
      " 21  county        0 non-null       float64\n",
      " 22  state         539759 non-null  object \n",
      " 23  lat           530785 non-null  float64\n",
      " 24  long          530785 non-null  float64\n",
      "dtypes: float64(5), int64(2), object(18)\n",
      "memory usage: 103.0+ MB\n",
      "None\n",
      "\n",
      "---------------------------------\n",
      "AFTER Column name cleanup:\n",
      "---------------------------------\n",
      "TrueCar dataframe columns:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 852122 entries, 0 to 852121\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   Price      852122 non-null  int64 \n",
      " 1   Year       852122 non-null  int64 \n",
      " 2   Mileage    852122 non-null  int64 \n",
      " 3   State      852122 non-null  object\n",
      " 4   Vin        852122 non-null  object\n",
      " 5   Make       852122 non-null  object\n",
      " 6   Model      852122 non-null  object\n",
      " 7   Condition  852122 non-null  object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 52.0+ MB\n",
      "None\n",
      "\n",
      "Craigslist dataframe columns:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 539759 entries, 0 to 539758\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   Price      539759 non-null  int64  \n",
      " 1   Year       538772 non-null  float64\n",
      " 2   Mileage    440783 non-null  float64\n",
      " 3   State      539759 non-null  object \n",
      " 4   Vin        315349 non-null  object \n",
      " 5   Make       516175 non-null  object \n",
      " 6   Model      531746 non-null  object \n",
      " 7   Condition  303707 non-null  object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 32.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Cleanup columns\n",
    "#   1. Examine columns and remove unneeded columns\n",
    "#   2. Rename columns to make the two datasets consistent\n",
    "#   3. Reorder columns to make the two datasets consistent\n",
    "\n",
    "# Print Before summary\n",
    "print(\"---------------------------------\")\n",
    "print(\"BEFORE Column name cleanup:\")\n",
    "print(\"---------------------------------\")\n",
    "print(\"TrueCar dataframe columns:\")\n",
    "print(truecar_df.info())\n",
    "print(\"\\nCraigslist dataframe columns:\")\n",
    "print(craigslist_df.info())\n",
    "\n",
    "# Drop unneeded columns\n",
    "truecar_df.drop(['City'], axis=1, inplace=True)\n",
    "\n",
    "# Drop unneeded columns\n",
    "craigslist_df.drop(['id', 'url', 'region', 'region_url', 'cylinders',\\\n",
    "                    'fuel', 'title_status', 'transmission', 'drive',\\\n",
    "                    'size', 'type', 'paint_color', 'image_url',\\\n",
    "                    'description', 'county', 'lat', 'long'], axis=1, inplace=True)\n",
    "\n",
    "# Add Condition column to TrueCar dataframe, used later so we can concatentate the two dataframes \n",
    "truecar_df[\"Condition\"] = \"\"\n",
    "\n",
    "# Rename Craigslist columns to be consistent with TrueCar\n",
    "craigslist_df.rename(columns={\"price\" : \"Price\",\n",
    "                              \"year\" : \"Year\",\n",
    "                              \"manufacturer\" : \"Make\",\n",
    "                              \"model\" : \"Model\",\n",
    "                              \"condition\" : \"Condition\",\n",
    "                              \"odometer\" : \"Mileage\",\n",
    "                              \"vin\" : \"Vin\",\n",
    "                              \"state\" : \"State\"}, inplace=True)\n",
    "\n",
    "# Reorganize Craigslist columns to match cars1\n",
    "craigslist_df = craigslist_df[[\"Price\", \"Year\", \"Mileage\", \"State\", \"Vin\", \"Make\", \"Model\", \"Condition\"]]\n",
    "\n",
    "# Print After summary\n",
    "print(\"\\n---------------------------------\")\n",
    "print(\"AFTER Column name cleanup:\")\n",
    "print(\"---------------------------------\")\n",
    "print(\"TrueCar dataframe columns:\")\n",
    "print(truecar_df.info())\n",
    "print(\"\\nCraigslist dataframe columns:\")\n",
    "print(craigslist_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE Regarding Timing of Concatentation\n",
    "* At this time, we could concatenate the two dataframes.\n",
    "* However, we want to later choose random sets of rows for testing and production from each dataset.\n",
    "  * For example, to ensure we have x number of rows from the TrueCar dataset and y rows from the Craiglist dataset, we need to continue to keep them separate until later\n",
    "* The main reason for this is to reduce the number of API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup data in columns that have text\n",
    "#   1. Remove any whitespace (trim or strip) from string values\n",
    "#   2. Capitalize values in these text columns consistently\n",
    "#   3. Replace any NaNs in the Condition column with the text \"Unknown\"\n",
    "\n",
    "# Strip any whitespace from strings\n",
    "truecar_df[\"State\"] = truecar_df[\"State\"].str.strip()\n",
    "truecar_df[\"Vin\"] = truecar_df[\"Vin\"].str.strip()\n",
    "truecar_df[\"Make\"] = truecar_df[\"Make\"].str.strip()\n",
    "truecar_df[\"Model\"] = truecar_df[\"Model\"].str.strip()\n",
    "truecar_df[\"Condition\"] = truecar_df[\"Condition\"].str.strip()\n",
    "\n",
    "craigslist_df[\"State\"] = craigslist_df[\"State\"].str.strip()\n",
    "craigslist_df[\"Vin\"] = craigslist_df[\"Vin\"].str.strip()\n",
    "craigslist_df[\"Make\"] = craigslist_df[\"Make\"].str.strip()\n",
    "craigslist_df[\"Model\"] = craigslist_df[\"Model\"].str.strip()\n",
    "craigslist_df[\"Condition\"] = craigslist_df[\"Condition\"].str.strip()\n",
    "\n",
    "# Capitalize values in these text columns consistently\n",
    "truecar_df[\"Make\"] = truecar_df[\"Make\"].str.title()\n",
    "truecar_df[\"Model\"] = truecar_df[\"Model\"].str.title()\n",
    "truecar_df[\"Condition\"] = truecar_df[\"Condition\"].str.title()\n",
    "truecar_df[\"State\"] = truecar_df[\"State\"].str.upper()\n",
    "\n",
    "craigslist_df[\"Make\"] = craigslist_df[\"Make\"].str.title()\n",
    "craigslist_df[\"Model\"] = craigslist_df[\"Model\"].str.title()\n",
    "craigslist_df[\"Condition\"] = craigslist_df[\"Condition\"].str.title()\n",
    "craigslist_df[\"State\"] = craigslist_df[\"State\"].str.upper()\n",
    "\n",
    "# Replace the NaNs in Condition with Unknown\n",
    "craigslist_df.loc[craigslist_df[\"Condition\"].isnull(),\"Condition\"] = \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of TrueCar problem rows found: 0\n",
      "Number of Craigslist problem rows found: 248071\n",
      "    Number of Craigslist rows BEFORE removing problem rows: 539759\n",
      "    Number of Craigslist rows AFTER removing problem rows: 291688\n"
     ]
    }
   ],
   "source": [
    "# Find problem rows for each dataset.  These are records with NaNs in any of the columns\n",
    "#   1. Find rows with NaNs\n",
    "#   2. If NaNs are found, extract these rows as CSVs for separate analysis by the client\n",
    "#   3. Remove these rows from our dataframes\n",
    "\n",
    "# Paths to our output files\n",
    "truecar_problem_records = os.path.join(\".\", \"ClientAnalysisNeeded\", \"truecar_problems.csv\")\n",
    "craigslist_problem_records = os.path.join(\".\", \"ClientAnalysisNeeded\", \"craigslist_problems.csv\")\n",
    "\n",
    "# Find rows with NaNs in TrueCar dataset\n",
    "truecar_is_NaN = truecar_df.isnull()\n",
    "truecar_row_has_NaN = truecar_is_NaN.any(axis=1)\n",
    "truecar_rows_with_NaN = truecar_df[truecar_row_has_NaN]\n",
    "\n",
    "# Find rows with NaNs in Craigslist dataset\n",
    "craigslist_is_NaN = craigslist_df.isnull()\n",
    "craigslist_row_has_NaN = craigslist_is_NaN.any(axis=1)\n",
    "craigslist_rows_with_NaN = craigslist_df[craigslist_row_has_NaN]\n",
    "\n",
    "# If problems exist, create CSV file then remove the problem records from the dataset\n",
    "print(f\"Number of TrueCar problem rows found: {truecar_rows_with_NaN.shape[0]}\")\n",
    "if truecar_rows_with_NaN.shape[0] > 0:\n",
    "    print(f\"    Number of TrueCar rows BEFORE removing problem rows: {truecar_df.shape[0]}\")\n",
    "    truecar_rows_with_NaN.to_csv(truecar_problem_records, header=True)\n",
    "    problem_index_vals = list(truecar_rows_with_NaN.index.values)\n",
    "    truecar_df = truecar_df.loc[~truecar_df.index.isin(problem_index_vals), :]\n",
    "    print(f\"    Number of TrueCar rows AFTER removing problem rows: {truecar_df.shape[0]}\")\n",
    "    \n",
    "print(f\"Number of Craigslist problem rows found: {craigslist_rows_with_NaN.shape[0]}\")    \n",
    "if craigslist_rows_with_NaN.shape[0] > 0:\n",
    "    print(f\"    Number of Craigslist rows BEFORE removing problem rows: {craigslist_df.shape[0]}\")\n",
    "    craigslist_rows_with_NaN.to_csv(craigslist_problem_records, header=True)\n",
    "    problem_index_vals = list(craigslist_rows_with_NaN.index.values)\n",
    "    craigslist_df = craigslist_df.loc[~craigslist_df.index.isin(problem_index_vals), :]\n",
    "    print(f\"    Number of Craigslist rows AFTER removing problem rows: {craigslist_df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of TrueCar duplicate VINs found: 47\n",
      "    Number of TrueCar rows BEFORE removing duplicate VINs: 852122\n",
      "    Number of TrueCar rows AFTER removing duplicate VINs: 852075\n",
      "Number of Craigslist duplicate VINs found: 122626\n",
      "    Number of Craigslist rows BEFORE removing duplicate VINs: 291688\n",
      "    Number of Craigslist rows AFTER removing duplicate VINs: 169062\n"
     ]
    }
   ],
   "source": [
    "# Find and process duplicate VINs\n",
    "#   1. Find duplicate VIN records\n",
    "#   2. If duplicate VINs are found, extract these rows as CSVs for separate analysis by the client\n",
    "#   3. Remove these rows from our dataframes\n",
    "\n",
    "# Paths to our output files\n",
    "truecar_dup_vins = os.path.join(\".\", \"ClientAnalysisNeeded\", \"truecar_dup_vins.csv\")\n",
    "craigslist_dup_vins = os.path.join(\".\", \"ClientAnalysisNeeded\", \"craigslist_dup_vins.csv\")\n",
    "\n",
    "# For Truecar\n",
    "truecar_duplicateVinRows = truecar_df[truecar_df.duplicated([\"Vin\"])]\n",
    "print(f\"Number of TrueCar duplicate VINs found: {truecar_duplicateVinRows.shape[0]}\")\n",
    "if truecar_duplicateVinRows.shape[0] > 0:\n",
    "    print(f\"    Number of TrueCar rows BEFORE removing duplicate VINs: {truecar_df.shape[0]}\")\n",
    "    truecar_duplicateVinRows.to_csv(truecar_dup_vins, header=True)\n",
    "    \n",
    "    dup_vins_index_vals = list(truecar_duplicateVinRows.index.values)\n",
    "    truecar_df = truecar_df.loc[~truecar_df.index.isin(dup_vins_index_vals), :]\n",
    "    print(f\"    Number of TrueCar rows AFTER removing duplicate VINs: {truecar_df.shape[0]}\")\n",
    "\n",
    "# For Craigslist\n",
    "craigslist_duplicateVinRows = craigslist_df[craigslist_df.duplicated([\"Vin\"])]\n",
    "print(f\"Number of Craigslist duplicate VINs found: {craigslist_duplicateVinRows.shape[0]}\")\n",
    "if craigslist_duplicateVinRows.shape[0] > 0:\n",
    "    print(f\"    Number of Craigslist rows BEFORE removing duplicate VINs: {craigslist_df.shape[0]}\")\n",
    "    craigslist_duplicateVinRows.to_csv(craigslist_dup_vins, header=True)\n",
    "    \n",
    "    dup_vins_index_vals = list(craigslist_duplicateVinRows.index.values)\n",
    "    craigslist_df = craigslist_df.loc[~craigslist_df.index.isin(dup_vins_index_vals), :]\n",
    "    print(f\"    Number of Craigslist rows AFTER removing duplicate VINs: {craigslist_df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 169062 entries, 0 to 539733\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   Price      169062 non-null  int64 \n",
      " 1   Year       169062 non-null  int64 \n",
      " 2   Mileage    169062 non-null  int64 \n",
      " 3   State      169062 non-null  object\n",
      " 4   Vin        169062 non-null  object\n",
      " 5   Make       169062 non-null  object\n",
      " 6   Model      169062 non-null  object\n",
      " 7   Condition  169062 non-null  object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 11.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Ensure datatypes are consistent across the two datasets\n",
    "# Need to convert Craigslist \"Year\" and \"Mileage\" columns from float64 to int64\n",
    "\n",
    "# Define conversion dictionary\n",
    "conversion_dict = {\"Year\" : \"int64\",\n",
    "                   \"Mileage\" : \"int64\"}\n",
    "\n",
    "# Make the conversion\n",
    "craigslist_df = craigslist_df.astype(conversion_dict)\n",
    "\n",
    "# Confirm conversion\n",
    "craigslist_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrueCar VIN count by sales channel:\n",
      "Sales_Channel\n",
      "Auction      4557\n",
      "Public     847518\n",
      "Name: Vin, dtype: int64\n",
      "\n",
      "Craigslist VIN count by sales channel:\n",
      "Sales_Channel\n",
      "Auction      6233\n",
      "Public     162829\n",
      "Name: Vin, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create Sales Channel column and populate\n",
    "#   - Create column based on the \"Year\" column\n",
    "#   - If the car is >= 20 years old, then the sales channel should be \"Auction\",\n",
    "#   - otherwise the sales channel should be \"Public\"\n",
    "\n",
    "# Get current year\n",
    "current_datetime = datetime.datetime.now()\n",
    "current_year = current_datetime.year\n",
    "\n",
    "# Define Public vs Auction threshold\n",
    "public_vs_auction_threshold = 20\n",
    "\n",
    "# Define function to determine Auction vs Public based on current year\n",
    "def sales_or_auction(row):\n",
    "    if (current_year - row[\"Year\"] >= public_vs_auction_threshold):\n",
    "        val = \"Auction\"\n",
    "    else:\n",
    "        val = \"Public\"\n",
    "    return val\n",
    "\n",
    "# Apply function to the TrueCar dataset\n",
    "temp = truecar_df.copy()\n",
    "truecar_df = temp.copy()\n",
    "truecar_df[\"Sales_Channel\"] = truecar_df.apply(sales_or_auction, axis=1)\n",
    "\n",
    "# Apply function to the Craigslist dataset\n",
    "temp = craigslist_df.copy()\n",
    "craigslist_df = temp.copy()\n",
    "craigslist_df[\"Sales_Channel\"] = craigslist_df.apply(sales_or_auction, axis=1)\n",
    "\n",
    "# Get counts by sales channel for TrueCar\n",
    "truecar_sales_gb = truecar_df.groupby(\"Sales_Channel\").count()\n",
    "print(\"TrueCar VIN count by sales channel:\")\n",
    "print(truecar_sales_gb[\"Vin\"])\n",
    "\n",
    "# Get counts by sales channel for Craigslist\n",
    "craigslist_sales_gb = craigslist_df.groupby(\"Sales_Channel\").count()\n",
    "print(\"\\nCraigslist VIN count by sales channel:\")\n",
    "print(craigslist_sales_gb[\"Vin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Craigslist VIN count by sales channel after updated based on condition:\n",
      "Sales_Channel\n",
      "Auction      7360\n",
      "Public     161702\n",
      "Name: Vin, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Update sales channel based on Condition (applies to the Craigslist dataset only)\n",
    "\n",
    "# Define a list of Conditions that qualify for the Public sales channel\n",
    "# Anything not in this list will be assigned to the Auction sales channel\n",
    "public_sales_conditions = [\"New\", \"Excellent\", \"Like New\", \"Good\", \"Unknown\"]\n",
    "\n",
    "craigslist_df.loc[~craigslist_df['Condition'].isin(public_sales_conditions),\"Sales_Channel\"] = \"Auction\"\n",
    "craigslist_sales_gb = craigslist_df.groupby(\"Sales_Channel\").count()\n",
    "print(\"\\nCraigslist VIN count by sales channel after updated based on condition:\")\n",
    "print(craigslist_sales_gb[\"Vin\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign each vehicle to a TrueSafeCar.com main office based on the CSV input file provided by the client\n",
    "\n",
    "# Read in the State to Main Office assignment data from CSV\n",
    "main_office_df = pd.read_csv(main_office_input)\n",
    "\n",
    "# Drop any unneeded columns from the input CSV.  In this case, we don't need the full text name of each State\n",
    "main_office_df.drop(\"State\", axis=1, inplace=True)\n",
    "\n",
    "# Apply the main office assignment to the TrueCar dataframe and remove unnecessary column from the merge\n",
    "truecar_df = truecar_df.merge(main_office_df, left_on=\"State\", right_on=\"State Code\")\n",
    "truecar_df.drop([\"State Code\"], axis=1, inplace=True)\n",
    "\n",
    "# Apply the main office assignment to the TrueCar dataframe and remove unnecessary column from the merge\n",
    "craigslist_df = craigslist_df.merge(main_office_df, left_on=\"State\", right_on=\"State Code\")\n",
    "craigslist_df.drop([\"State Code\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUTPUT Cleaned Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare output files\n",
    "truecar_df_output_file = os.path.join(\".\", \"CleanedLargeDatasets\", \"truecar_df_cleaned_data.csv\")\n",
    "craigslist_df_output_file = os.path.join(\".\", \"CleanedLargeDatasets\", \"craigslist_df_cleaned_data.csv\")\n",
    "combined_df_output_file = os.path.join(\".\", \"CleanedLargeDatasets\", \"combined_df_cleaned_data.csv\")\n",
    "\n",
    "# Output each cleaned dataset to CSV\n",
    "truecar_df.to_csv(truecar_df_output_file, header=True)\n",
    "craigslist_df.to_csv(craigslist_df_output_file, header=True)\n",
    "\n",
    "# Concatenate the two datasets and output to CSV\n",
    "comb_cars_df = pd.concat([truecar_df, craigslist_df], ignore_index=True)\n",
    "\n",
    "# Output concatenated dataframe\n",
    "comb_cars_df.to_csv(combined_df_output_file, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE Test Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Test dataframes by randomly selecting from our main dataframes\n",
    "# Create CSV output for dataframes\n",
    "\n",
    "# Declare output files\n",
    "truecar_test_file = os.path.join(\".\", \"TrimmedDatasets\", \"truecar_test_data.csv\")\n",
    "craigslist_test_file = os.path.join(\".\", \"TrimmedDatasets\", \"craigslist_test_data.csv\")\n",
    "\n",
    "# Declare our sizes for Test and Production dataframe\n",
    "test_dataframe_size = 50\n",
    "\n",
    "# Create TrueCar Test and Production dataframes\n",
    "truecar_random_index = np.random.choice(truecar_df.shape[0], replace=False, size=test_dataframe_size)\n",
    "truecar_test_df = truecar_df.iloc[truecar_random_index]\n",
    "\n",
    "# Create Craigslist Test and Production dataframes\n",
    "craigslist_random_index = np.random.choice(craigslist_df.shape[0], replace=False, size=test_dataframe_size)\n",
    "craigslist_test_df = craigslist_df.iloc[craigslist_random_index]\n",
    "\n",
    "# Output dataframes as CSVs\n",
    "truecar_test_df.to_csv(truecar_test_file, header=True)\n",
    "craigslist_test_df.to_csv(craigslist_test_file, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create merged Test dataframe\n",
    "# Create CSV output for combined dataframe\n",
    "\n",
    "# Declare output files\n",
    "comb_test_file = os.path.join(\".\", \"TrimmedDatasets\", \"combined_test_data.csv\")\n",
    "\n",
    "# Perform concatentations\n",
    "comb_test_df = pd.concat([truecar_test_df, craigslist_test_df], ignore_index=True)\n",
    "\n",
    "# Output dataframes as CSVs\n",
    "comb_test_df.to_csv(comb_test_file, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NHTSA.GOV API Call - Obtain Clean Make and Model\n",
    "Note: Due to the volume of cars in our database, we will be limiting tasks that involve API calls\n",
    "to a subset of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use NHTSA VIN Decoder API to get a clean Make and Model for the Recall API calls \n",
    "# NOTE: VIN DECODER ONLY WORKS FOR YEARS 1981 AND NEWER\n",
    "#       FOR INVALID VINs, THE DECODER WILL HAVE [\"Results\"][0][\"ErrorCode\"] != 0\n",
    "#       FOR VALID VINs, THE DECODER WILL HAVE [\"Results\"][0][\"ErrorCode\"] = 0\n",
    "\n",
    "vin_base_url = \"https://vpic.nhtsa.dot.gov/api/vehicles/decodevinvalues/\"\n",
    "earliest_valid_year = 1981\n",
    "\n",
    "# Create column to indicate whether VIN has been verified or not\n",
    "comb_test_df[\"Vin_Verified\"] = False\n",
    "\n",
    "# Iterate through dataframe\n",
    "for index, row in comb_test_df.iterrows(): \n",
    "    if row[\"Year\"] >= earliest_valid_year:\n",
    "        # Form query URL for current Vin and Year\n",
    "        current_vin = row[\"Vin\"]\n",
    "        current_year = row[\"Year\"]\n",
    "        vin_query_url = f\"{vin_base_url}{current_vin}?format=json&modelyear={current_year}\"\n",
    "\n",
    "        try:\n",
    "            # Make API call\n",
    "            response = requests.get(vin_query_url).json()\n",
    "\n",
    "            # Check response object\n",
    "            response_code = response[\"Results\"][0][\"ErrorCode\"]\n",
    "            if (response_code == \"0\"):\n",
    "                # Successful response\n",
    "                # Set Vin Verified to True\n",
    "                comb_test_df.loc[index, \"Vin_Verified\"] = True\n",
    "\n",
    "                # Update Make and Model from API call results\n",
    "                comb_test_df.loc[index, \"Make\"]  = response[\"Results\"][0][\"Make\"]\n",
    "                comb_test_df.loc[index, \"Model\"] = response[\"Results\"][0][\"Model\"]\n",
    "        except:\n",
    "            print(\"-------------------------------------------------------\")\n",
    "            print(f\"An error occurred for: {current_vin} {current_year}:\")\n",
    "            print(\"-------------------------------------------------------\")       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NHTSA.GOV API Call - Obtain Recall Data\n",
    "Note: Due to the volume of cars in our database, we will be limiting tasks that involve API calls\n",
    "to a subset of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use NHTSA Recall API to get recall information for each Vin Verified row of our dataframe\n",
    "\n",
    "recall_base_url = f\"https://one.nhtsa.gov/webapi/api/Recalls/vehicle/\"\n",
    "\n",
    "comb_test_df[\"Recall_Count\"] = 0\n",
    "\n",
    "# Iterate through dataframe\n",
    "for index, row in comb_test_df.iterrows(): \n",
    "    if row[\"Vin_Verified\"] == True:\n",
    "        # Only make Recall API calls for Vin Verified rows\n",
    "        \n",
    "        # Form query URL for current Year, Make, and Model\n",
    "        current_year = row[\"Year\"]\n",
    "        current_make = row[\"Make\"]\n",
    "        current_model = row[\"Model\"]\n",
    "        current_vin = row[\"Vin\"]\n",
    "\n",
    "        recall_query_url = f\"{recall_base_url}modelyear/{current_year}/make/{current_make}/model/{current_model}?format=json\"\n",
    "\n",
    "        try:\n",
    "            # Make API call and store response\n",
    "            response = requests.get(recall_query_url).json()\n",
    "\n",
    "            if (response[\"Count\"] > 0):\n",
    "                # Recall data found\n",
    "                comb_test_df.loc[index, \"Recall_Count\"] = response[\"Count\"]\n",
    "                \n",
    "        except json.decoder.JSONDecodeError:\n",
    "            print(\"-------------------------------------------------------\")\n",
    "            print(f\"JSON Decode error occurred for: {current_vin} {current_year} {current_make} {current_model}:\")\n",
    "            print(\"-------------------------------------------------------\")\n",
    "        except:\n",
    "            print(\"-------------------------------------------------------\")\n",
    "            print(f\"Other error occurred for: {current_vin} {current_year} {current_make} {current_model}:\")\n",
    "            print(\"-------------------------------------------------------\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use NHTSA 5 Star Safety Ratings API to get the overall safety rating for our Vin-verified cars\n",
    "\n",
    "get_vehicle_id_base_url = f\"https://webapi.nhtsa.gov/api/SafetyRatings/modelyear/\"\n",
    "get_safety_rating_base_url = f\"https://webapi.nhtsa.gov/api/SafetyRatings/VehicleId/\"\n",
    "\n",
    "# Create column in our dataframe for the safety rating\n",
    "comb_test_df[\"Safety_Rating\"] = \"\"\n",
    "\n",
    "# Iterate through dataframe\n",
    "for index, row in comb_test_df.iterrows(): \n",
    "    if row[\"Vin_Verified\"] == True:\n",
    "        # Step 1 - Retrieve the NHTSA vehicle ID for our vehicle\n",
    "        # Example: https://webapi.nhtsa.gov/api/SafetyRatings/modelyear/2013/make/Acura/model/rdx?format=json\n",
    "        current_year = row[\"Year\"]\n",
    "        current_make = row[\"Make\"]\n",
    "        current_model = row[\"Model\"]\n",
    "        current_vin = row[\"Vin\"]\n",
    "\n",
    "        get_vehicle_id_url = f\"{get_vehicle_id_base_url}{current_year}/make/{current_make}/model/{current_model}?format=json\"\n",
    "\n",
    "        try:\n",
    "            # Make API call\n",
    "            response = requests.get(get_vehicle_id_url).json()\n",
    "            # Count of records returned = response[\"Count\"]\n",
    "            response_count = response[\"Count\"]\n",
    "            if (response_count > 0):\n",
    "                # Get the first vehicle ID\n",
    "                current_vehicle_ID = response[\"Results\"][0][\"VehicleId\"]\n",
    "\n",
    "                # Step 2 - Using the NHTSA vehicle ID, retrieve the Overall Safety Rating for our vehicle\n",
    "                # Example: https://webapi.nhtsa.gov/api/SafetyRatings/VehicleId/7520?format=json\n",
    "                get_safety_rating_url = f\"{get_safety_rating_base_url}{current_vehicle_ID}?format=json\"\n",
    "\n",
    "                try:\n",
    "                    response = requests.get(get_safety_rating_url).json()\n",
    "                    response_count = response[\"Count\"]\n",
    "                    if(response_count > 0):\n",
    "                        current_safety_rating = response[\"Results\"][0][\"OverallRating\"]\n",
    "                        comb_test_df.loc[index, \"Safety_Rating\"] = current_safety_rating\n",
    "                except:\n",
    "                    print(\"-------------------------------------------------------\")\n",
    "                    print(f\"Error occurred getting Safety Raing for: {current_vin} {current_year} {current_make} {current_model}:\")\n",
    "                    print(\"-------------------------------------------------------\")\n",
    "                   \n",
    "        except:\n",
    "            print(\"-------------------------------------------------------\")\n",
    "            print(f\"Error occurred getting vehicle ID for: {current_vin} {current_year} {current_make} {current_model}:\")\n",
    "            print(\"-------------------------------------------------------\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The safety ratings found: ['Not Rated', '', '4', '5']\n"
     ]
    }
   ],
   "source": [
    "# NOTE: There were no vehicles with a Safety Rating lower than 3\n",
    "safety_ratings_found = list(comb_test_df[\"Safety_Rating\"].unique())\n",
    "print(f\"The safety ratings found: {safety_ratings_found}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUTPUT Updated Test Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare output files\n",
    "comb_test_updated_file = os.path.join(\".\", \"TrimmedDatasets\", \"combined_test_updated_data.csv\")\n",
    "\n",
    "# Output dataframe as CSV\n",
    "comb_test_df.to_csv(comb_test_updated_file, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
